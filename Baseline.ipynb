{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_dir = './Quora_question_pair_partition/'\n",
    "train_dir = base_dir + 'train.tsv'\n",
    "dev_dir = base_dir + 'dev.tsv'\n",
    "test_dir = base_dir + 'test.tsv'\n",
    "word_dir = base_dir + 'wordvec.txt'\n",
    "words_vec = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "40000\n",
      "45000\n",
      "50000\n",
      "55000\n",
      "60000\n",
      "65000\n",
      "70000\n",
      "75000\n",
      "80000\n",
      "85000\n",
      "90000\n",
      "95000\n",
      "100000\n",
      "105000\n"
     ]
    }
   ],
   "source": [
    "def loadWordDic():\n",
    "    with open(word_dir, 'r') as words:\n",
    "        tweets_reader = csv.reader(words, delimiter=' ')\n",
    "        cnt = 0\n",
    "        for row in tweets_reader:\n",
    "            words_vec[row[0]] = np.array([float(x) for x in row[1:]]).reshape((1,300))\n",
    "            cnt += 1\n",
    "            if cnt%5000 == 0:\n",
    "                print(cnt)\n",
    "loadWordDic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "def loadData():\n",
    "    train_df = pd.read_csv(train_dir,sep='\\t', header=None, names=['label','q1','q2','id'])\n",
    "    train_X, train_y = train_df[['q1','q2']], train_df['label']\n",
    "    dev_df = pd.read_csv(dev_dir,sep='\\t', header=None, names=['label','q1','q2','id'])\n",
    "    dev_X, dev_y = dev_df[['q1','q2']], dev_df['label']\n",
    "    test_df = pd.read_csv(test_dir,sep='\\t', header=None, names=['label','q1','q2','id'])\n",
    "    test_X, test_y = test_df[['q1','q2']], test_df['label']\n",
    "    return train_X, train_y, dev_X, dev_y, test_X, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    feature_names = []\n",
    "    \n",
    "    # number of words\n",
    "    df['cnt'] = df.apply(lambda row:abs(len(row['q1'].split(' '))-len(row['q2'].split(' '))),axis=1)\n",
    "    feature_names.append('cnt')\n",
    "    \n",
    "    # distance between sentences\n",
    "    df['dis'] = df.apply(dis, axis = 1)\n",
    "    feature_names.append('dis')\n",
    "    \n",
    "    # magic feature: question frequency\n",
    "    \n",
    "    print(\"Finish generating features\")\n",
    "    \n",
    "    return feature_names, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## train model\n",
    "def train(train_X, train_y,para):\n",
    "    \n",
    "    feature_names, df = generate_features(train_X)\n",
    "    \n",
    "    clf = tree.DecisionTreeClassifier(max_depth=para['max_depth'])\n",
    "    \n",
    "    clf.fit(df[feature_names],train_y)\n",
    "    \n",
    "    acc = clf.score(df[feature_names],train_y)\n",
    "    \n",
    "    print(\"Accuracy on the training set:\", acc)\n",
    "    \n",
    "    return acc, clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## select hyper parameters on the dev set\n",
    "def select_model(train_X, train_y, dev_X, dev_y, paras):\n",
    "    max_acc = 0\n",
    "    best_model = None\n",
    "    for para in paras:\n",
    "        train_acc, model = train(train_X, train_y, para)\n",
    "        feature_names, df = generate_features(dev_X)\n",
    "        dev_acc = model.score(df[feature_names], dev_y)\n",
    "        if dev_acc > max_acc:\n",
    "            max_acc = dev_acc\n",
    "            best_model = model\n",
    "    return max_acc, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## evaluate on the test set\n",
    "def test(test_X, test_y, model):\n",
    "    feature_names, df = generate_features(test_X)\n",
    "    acc = model.score(df[feature_names], test_y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # read data\n",
    "    train_X, train_y, dev_X, dev_y, test_X, test_y = loadData()\n",
    "    print(\"Finish loading data\")\n",
    "    \n",
    "    paras = [{'max_depth':100}]\n",
    "    \n",
    "    acc_dev, model = select_model(train_X, train_y, dev_X, dev_y, paras)\n",
    "    print(\"Accuracy on the development set is:\",acc_dev)\n",
    "    \n",
    "    acc_test = test(test_X, test_y, model)\n",
    "    print(\"Accuracy on the test set is:\",acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################################Helper function############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dis(row): \n",
    "    words1 = row['q1'].split(' ')\n",
    "    words2 = row['q2'].split(' ')\n",
    "    v1 = np.zeros((1,300))\n",
    "    cnt1 = 0\n",
    "    v2 = np.zeros((1,300))\n",
    "    cnt2 = 0\n",
    "    for word in words1:\n",
    "        if word.lower() in words_vec:\n",
    "            cnt1 += 1\n",
    "            v1 += words_vec[word.lower()]\n",
    "        else:\n",
    "            print(\"Skip word \",word)\n",
    "    for word in words2:\n",
    "        if word.lower() in words_vec:\n",
    "            cnt2 += 1\n",
    "            v2 += words_vec[word.lower()]\n",
    "        else:\n",
    "            print(\"Skip word\",word)\n",
    "    return (v1 / cnt1 - v2  / cnt2).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
